# -*- coding: utf-8 -*-
"""web_voyager.ipynb
http://localhost:3000
Automatically generated by Colab.

uvicorn src.app.api.api:app --reload   

Original file is located at
    https://colab.research.google.com/github/albeorla/google-collab-notebooks/blob/main/web_voyager.ipynb
"""

import json
import os
import asyncio
import base64
import platform
import re
from typing import List, Optional, TypedDict
from dotenv import load_dotenv
from urllib.parse import urlparse

from langchain_core.messages import BaseMessage, SystemMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough, RunnableLambda, chain as chain_decorator
from langchain_openai import ChatOpenAI
from langchain import hub
from langgraph.graph import END, StateGraph
from playwright.async_api import Page, async_playwright

# Load environment variables
load_dotenv()

# Set up environment variables
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "Web-Voyager"
os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGCHAIN_API_KEY")
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# Define types
class BBox(TypedDict):
    x: float
    y: float
    text: str
    type: str
    ariaLabel: str

class Prediction(TypedDict):
    action: str # 
    args: Optional[List[str]]

class AgentState(TypedDict):
    page: Page # single page in browser, provides ways to interact with web pages
    input: str
    img: str
    bboxes: List[BBox]  # list of bounding boxes
    prediction: Prediction # another class defined above
    scratchpad: List[BaseMessage] # acts as the memory for the agent
    observation: str
    current_url: str
    action_history: List[dict]  # New field to store action history
    page_height: int  # Full page height
    viewport_height: int  # Visible viewport height
    html_content: str
    text_content: str
    app_metadata: dict  # New field to store app metadata

from pydantic import BaseModel

from pydantic import BaseModel
from typing import List, Optional

class ScreenLocation(BaseModel):
    x: float
    y: float
    width: float
    height: float

class Step(BaseModel):
    thought: str
    action: str
    instruction: str
    element_description: Optional[str] = None
    screen_location: Optional[dict] = None
    hover_before_action: bool = False
    text_input: Optional[str] = None

class AgentResponse(BaseModel):
    steps: List[Step]
    final_answer: Optional[str] = None
    current_url: str

###############
# AGENT TOOLS #
###############

# Define tools
async def click(state: AgentState):
    page = state["page"] # grab the page in browser
    # grab the action string list, args determined by agent b4 called
    click_args = state["prediction"]["args"]
    # if click_args above doesn't exist, click_args is expected to have one argument
    if click_args is None or len(click_args) != 1:
        return f"Failed to click bounding box labeled as number {click_args}"
    # accesses first element in click_args list, converts to int. alr decided what to click
    bbox_id = int(click_args[0])
    # access specific bounding box information
    try:
        bbox = state["bboxes"][bbox_id]
    except:
        return f"Error: no bbox for : {bbox_id}"
    # grab x and y coordinates
    x, y = bbox["x"], bbox["y"]
    # page.mouse.click() from playwrite object
    await page.mouse.click(x, y)
    return f"Clicked {bbox_id}" # returns a string

async def type_text(state: AgentState):
    # Get the page object from the state
    page = state["page"]
    # Get the typing arguments from the state
    type_args = state["prediction"]["args"]
    # Check if the arguments are valid
    if type_args is None or len(type_args) != 2:
        return f"Failed to type in element from bounding box labeled as number {type_args}"
    # Get the bounding box ID
    bbox_id = int(type_args[0])
    # Get the bounding box information
    bbox = state["bboxes"][bbox_id]
    # Extract x and y coordinates from the bounding box
    x, y = bbox["x"], bbox["y"]
    # Get the text to be typed
    text_content = type_args[1]
    # Click on the element at the specified coordinates
    await page.mouse.click(x, y)
    # Determine the "Select All" keyboard shortcut based on the operating system
    select_all = "Meta+A" if platform.system() == "Darwin" else "Control+A"
    # Select all existing text in the element
    await page.keyboard.press(select_all)
    # Delete the selected text
    await page.keyboard.press("Backspace")
    # Type the new text content
    await page.keyboard.type(text_content)
    # Press Enter to submit the input
    await page.keyboard.press("Enter")
    # Return a success message
    return f"Typed {text_content} and submitted"


async def scroll(state: AgentState):
    page = state["page"]
    scroll_args = state["prediction"]["args"]
    if scroll_args is None or len(scroll_args) != 2:
        return "Failed to scroll due to incorrect arguments. Please specify target and direction."

    target, direction = scroll_args

    if target.upper() == "WINDOW":
        vertical_scroll_amount = 500
        horizontal_scroll_amount = 300
        if direction.lower() == "up":
            scroll_x, scroll_y = 0, -vertical_scroll_amount
        elif direction.lower() == "down":
            scroll_x, scroll_y = 0, vertical_scroll_amount
        elif direction.lower() == "left":
            scroll_x, scroll_y = -horizontal_scroll_amount, 0
        elif direction.lower() == "right":
            scroll_x, scroll_y = horizontal_scroll_amount, 0
        else:
            return f"Invalid scroll direction: {direction}"
        await page.evaluate(f"window.scrollBy({scroll_x}, {scroll_y})")
    else:
        try:
            target_id = int(target)
            bbox = state["bboxes"][target_id]
            x, y = bbox["x"], bbox["y"]
            vertical_scroll_amount = 200
            horizontal_scroll_amount = 100
            if direction.lower() == "up":
                delta_x, delta_y = 0, -vertical_scroll_amount
            elif direction.lower() == "down":
                delta_x, delta_y = 0, vertical_scroll_amount
            elif direction.lower() == "left":
                delta_x, delta_y = -horizontal_scroll_amount, 0
            elif direction.lower() == "right":
                delta_x, delta_y = horizontal_scroll_amount, 0
            else:
                return f"Invalid scroll direction: {direction}"
            await page.mouse.move(x, y)
            await page.mouse.wheel(delta_x, delta_y)
        except ValueError:
            return f"Invalid target for scrolling: {target}"
        except IndexError:
            return f"Invalid bounding box ID: {target}"

    return f"Scrolled {direction} in {'window' if target.upper() == 'WINDOW' else f'element {target}'}"

async def wait(state: AgentState):
    sleep_time = 5
    # asyncio allows other funcs to continue while waiting
    await asyncio.sleep(sleep_time)
    return f"Waited for {sleep_time}s."

async def go_back(state: AgentState):
    page = state["page"]
    # playwright function
    await page.go_back()
    return f"Navigated back a page to {page.url}."

async def to_google(state: AgentState):
    page = state["page"]
    await page.goto("https://google.com")
    return "Navigated to Google."

async def to_home(state: AgentState):
    page = state["page"]
    await page.goto("https://tour-guide-liard.vercel.app/")
    return "Navigated to home page."


# Define mark_page function, THIS MARKS BOUNDING BOXES.
# done with the mark_page.js file
# Read mark_page.js
with open("/Users/williamphan/Desktop/tourguide/src/app/api/mark_page.js") as f:
    mark_page_script = f.read()

# decorator for chaining operations
# a way to wrap a function with another function, adding functionality before 
# or after the wrapped function executes
@chain_decorator
# asynchronous function to mark elements on the page
async def mark_page(page):
    await page.evaluate(mark_page_script)
    for _ in range(10):
        try:
            bboxes = await page.evaluate("markPage()")
            break
        except:
            await asyncio.sleep(2)
    screenshot = await page.screenshot()
    page_height = await page.evaluate("() => document.documentElement.scrollHeight")
    viewport_height = await page.evaluate("() => window.innerHeight")
    
    # Get HTML content
    html_content = await page.content()
    
    # Extract text content
    text_content = await page.evaluate("() => document.body.innerText")
    
    return {
        "img": base64.b64encode(screenshot).decode(),
        "bboxes": bboxes,
        "page_height": page_height,
        "viewport_height": viewport_height,
        "html_content": html_content,
        "text_content": text_content,
    }


# Define agent functions
async def annotate(state):
    marked_page = await mark_page.with_retry().ainvoke(state["page"])
    current_url = state["page"].url
    return {**state, **marked_page, "current_url": current_url}


# define function that takes a state parameter
def format_descriptions(state):
    # initialize an empty list to store formatted labels
    labels = []
    # iterate over bounding boxes in state, with index
    for i, bbox in enumerate(state["bboxes"]):
        # get ariaLabel if it exists, otherwise empty string
        text = bbox.get("ariaLabel") or ""
        # if text is empty or only whitespace, use bbox text instead
        if not text.strip():
            text = bbox["text"]
        # get the type of the element
        el_type = bbox.get("type")
        # append formatted string to labels list
        labels.append(f'{i} (<{el_type}/>): "{text}"')
    # create a string of all labels, joined by newlines
    bbox_descriptions = "\nValid Bounding Boxes:\n" + "\n".join(labels)
    
    # Format action history
    action_history = state.get("action_history", [])
    formatted_history = "\n".join([f"{a['step']}. {a['action']} {a['args']} (URL: {a['url']})" for a in action_history])
    
    page_info = f"Page height: {state['page_height']}px, Viewport height: {state['viewport_height']}px"
    
    # Include a summary of the text content
    text_summary = state['text_content'][:500] + "..." if len(state['text_content']) > 500 else state['text_content']
    
    # Extract available routes from app metadata
    available_routes = [route['path'] for route in state['app_metadata'].get('routes', [])]
    
    return {**state, "bbox_descriptions": bbox_descriptions, "action_history": formatted_history, "page_info": page_info, "text_summary": text_summary, "available_routes": available_routes}


def parse(text: str) -> dict:
    action_prefix = "Action: "
    if not text.strip().split("\n")[-1].startswith(action_prefix):
        return {"action": "retry", "args": f"Could not parse LLM Output: {text}"}
    action_block = text.strip().split("\n")[-1]

    action_str = action_block[len(action_prefix):]
    split_output = action_str.split(" ", 1)
    if len(split_output) == 1:
        action, action_input = split_output[0], None
    else:
        action, action_input = split_output
    action = action.strip()
    if action_input is not None:
        action_input = [inp.strip().strip("[]") for inp in action_input.strip().split(";")]
    return {"action": action, "args": action_input}


"""
crucial for maintaining the agent's "memory" and providing it with a structured history of its interactions. This history is vital for the agent to perform complex, multi-step tasks on web pages, as it allows the agent to reference past actions, understand the current context, and make more informed decisions about what to do next.
"""

def update_scratchpad(state: AgentState):
    # Get the existing scratchpad from the state, if any
    old = state.get("scratchpad")
    action_history = state.get("action_history", [])
    
    if old:
        # If there's an existing scratchpad, get its content
        txt = old[0].content
        # Extract the last line of the existing content
        last_line = txt.rsplit("\n", 1)[-1]
        # Extract the step number from the last line and increment it
        step = int(re.match(r"\d+", last_line).group()) + 1
    else:
        # If there's no existing scratchpad, initialize with a header
        txt = "Previous action observations:\n"
        # Start with step 1
        step = 1
    
    # Add the new observation to the text, with the current step number
    txt += f"\n{step}. {state['observation']}"
    
    # Add the current action to the history
    action_history.append({
        "step": step,
        "action": state['prediction']['action'],
        "args": state['prediction']['args'],
        "url": state['current_url']
    })
    
    # Limit the history to the last 10 actions
    action_history = action_history[-10:]
    
    # Return updated state with new scratchpad content
    # The scratchpad is a list containing a single SystemMessage
    return {**state, "scratchpad": [SystemMessage(content=txt)], "action_history": action_history}

# Set up the agent
# https://smith.langchain.com/hub/wfh/web-voyager?organizationId=2fe448c8-5ad1-583b-96a3-e1a7e2c8b466
# prompt = hub.pull("wfh/web-voyager")

custom_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a web navigation assistant. Your task is to guide the user based on their specific query or request. 
    In each iteration, you will receive an Observation that includes a screenshot of a webpage, some texts, the current URL, and metadata about the application structure.
    This screenshot will feature Numerical Labels placed in the TOP LEFT corner of each Web Element. 
    Carefully analyze the visual information, HTML content, the current URL, and the app metadata to determine your next action.

    Current goal: {input}

    IMPORTANT: Always consider the available routes provided in the app metadata. These routes represent all possible pages in the application, even if they're not visible on the current page.

    Choose one of the following actions:
    1. Click a Web Element.
    2. Delete existing content in a textbox and then type content.
    3. Scroll up, down, left, or right to explore parts of the page that might not be visible.
    4. Wait 
    5. Go back
    6. Navigate to a specific route (based on the available routes in the app metadata)
    7. Return to the home page to start over.
    8. Respond with the final answer

    Action should STRICTLY follow the format:
    - Click [Numerical_Label] 
    - Type [Numerical_Label]; [Content] 
    - Scroll [Numerical_Label or WINDOW]; [up or down or left or right] 
    - Wait 
    - GoBack
    - Navigate [route]
    - Home
    - ANSWER; [content]

    Key Guidelines:
    1) Execute only one action per iteration.
    2) When clicking or typing, ensure to select the correct bounding box.
    3) Numeric labels lie in the top-left corner of their corresponding bounding boxes and are colored the same.
    4) When you have completed the task or cannot proceed further, respond with ANSWER and do not perform any further actions.
    5) Pay close attention to the current URL, page content, HTML structure, and app metadata to determine if you've reached the desired page or information.
    6) Avoid repeating the same action multiple times in a row.
    7) If you find yourself in a loop, try a different approach or consider ending the task.
    8) Remember to scroll to explore parts of the page that might not be initially visible.
    9) When scrolling, always specify both the target (WINDOW or a Numerical_Label) and the direction (up, down, left, or right).
    10) Analyze the text content of the page to make informed decisions.
    11) Use the app metadata to understand the structure of the application and available routes.
    12) If a desired page or route (like '/product/chicken') is available in the metadata but not visible, use the 'Navigate' action to directly access it.

    Your reply should strictly follow the format:
    Thought: {{Your brief thoughts, including consideration of available routes}}
    Action: {{One Action format you choose}}"""),
    MessagesPlaceholder(variable_name="scratchpad"),
    ("human", "{input}\n\n{bbox_descriptions}\n\nCurrent URL: {current_url}\n\nPage Info: {page_info}\n\nText Content Summary:\n{text_summary}\n\nAction History:\n{action_history}\n\nAvailable Routes:\n{available_routes}"),
])

# Replace the existing prompt with the custom one
prompt = custom_prompt
llm = ChatOpenAI(model="gpt-4o-mini", max_tokens=4096)
agent = annotate | RunnablePassthrough.assign(
    # | is used to chain operations together in order
    # StrOutputParser() parses into string, parse processes stirng output into structured format.
    prediction=format_descriptions | prompt | llm | StrOutputParser() | parse
)

####################
# INITIALIZE GRAPH #
####################

# Set up/initialize the graph, pass in the agent state
graph_builder = StateGraph(AgentState)


# define node
graph_builder.add_node("agent", agent)
# sents the agent node to be first node to be excecuted when running
graph_builder.set_entry_point("agent")
# define other node
graph_builder.add_node("update_scratchpad", update_scratchpad)
# define edge between both the nodes
# Agent makes a decision
# An action is taken based on that decision
# The scratchpad is updated with the result of that action
# Control returns to the agent for the next decision
graph_builder.add_edge("update_scratchpad", "agent")

# agent tools
tools = {
    "Click": click,
    "Type": type_text,
    "Scroll": scroll,
    "Wait": wait,
    "GoBack": go_back,
    "Home": to_home, 
}

# Add nodes for each tool and connect them to the scratchpad update
for node_name, tool in tools.items():
    graph_builder.add_node(
        node_name,
        # Combine tool execution with formatting its output
        RunnableLambda(tool) | (lambda observation: {"observation": observation}),
    )
    # After each tool execution, update the scratchpad
    graph_builder.add_edge(node_name, "update_scratchpad")

# Function to select the next action based on the agent's prediction
def select_tool(state: AgentState):
    action = state["prediction"]["action"]
    if action.startswith("ANSWER"):
        return END  # End the process if the action is to answer
    if action == "retry":
        return "agent"  # Go back to the agent if a retry is needed
    return action  # Otherwise, return the action name (corresponding to a tool)

# Add conditional edges from the agent to other nodes based on select_tool function
graph_builder.add_conditional_edges("agent", select_tool)

# Compile the graph, making it ready for execution
graph = graph_builder.compile()

#############
# RUN AGENT #
#############
import os
from pinecone import Pinecone
from pinecone import Pinecone, ServerlessSpec
from openai import OpenAI
from typing import List
import openai
from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type

# Initialize Pinecone
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
index_name = os.getenv("PINECONE_INDEX_NAME")

if not index_name:
    raise ValueError("PINECONE_INDEX_NAME environment variable is not set")

# Check if the index exists, if not, create it
try:
    if index_name not in pc.list_indexes().names():
        pc.create_index(
            name=index_name,
            dimension=1536,  # OpenAI's ada-002 embedding dimension
            metric='cosine', # uses cosine similarity
          spec=ServerlessSpec(
                cloud="aws",
                region="us-east-1"
            ) 
        )
    index = pc.Index(index_name)
except Exception as e:
    print(f"Error initializing Pinecone: {str(e)}")
    raise

# Initialize OpenAI client
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@retry(
    wait=wait_random_exponential(min=1, max=60),
    stop=stop_after_attempt(6),
    retry=retry_if_exception_type(openai.RateLimitError)
)
def create_embedding_with_retry(text: str) -> List[float]:
    try:
        response = openai_client.embeddings.create(
            input=text,
            model="text-embedding-ada-002"
        )
        return response.data[0].embedding
    except openai.RateLimitError as e:
        print(f"Rate limit error: {e}")
        raise
    except openai.APIError as e:
        print(f"API error: {e}")
        if "billing_not_active" in str(e):
            print("Please check your OpenAI account billing status at https://platform.openai.com/account/billing")
            raise ValueError("OpenAI account is not active") from e
        raise

def create_embedding(text: str) -> List[float]:
    return create_embedding_with_retry(text)

def upsert_to_pinecone(file_path: str, file_content: str):
    embedding = create_embedding(file_content)
    index.upsert(vectors=[(file_path, embedding, {"content": file_content})])

def query_pinecone(query: str, top_k: int = 3):
    query_embedding = create_embedding(query)
    # Print the query and its embedding
    print(f"Query: {query}")
    print(f"Query Embedding (first 5 dimensions): {query_embedding[:5]}...")
    
    results = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)
    # Print the results
    print("\nTop matching documents:")
    for i, match in enumerate(results['matches'], 1):
        print(f"\n{i}. Score: {match['score']}")
        print(f"   ID: {match['id']}")
        print(f"   Content snippet: {match['metadata']['content'][:100]}...")
    
    return results

def index_documents(directory: str):
    print(f"Indexing documents from {directory}...")
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith(('.md', '.json')):
                file_path = os.path.join(root, file)
                with open(file_path, 'r') as f:
                    content = f.read()
                upsert_to_pinecone(file_path, content)
    print(f"Indexing complete for {directory}")

def index_single_file(file_path: str):
    print(f"Indexing single file: {file_path}")
    with open(file_path, 'r') as f:
        content = f.read()
    upsert_to_pinecone(file_path, content)
    print(f"Indexing complete for {file_path}")


"""
The system takes context from all the markdown and JSON files (via Pinecone), and it also uses GPT-4. It's not solely using GPT-4, but rather combining the power of vector search (Pinecone) with the language understanding and generation capabilities of GPT-4.

The reason why the augmented input attached to the question is because:
• The question is augmented with RELEVANT Pinecone data.
• This augmented input is passed to the agent.
• The agent uses the prompt (which includes placeholders for the input and other data) to structure its response.
"""

# Main function to run the agent
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

import logging
import json
from pydantic import BaseModel

from pydantic import BaseModel
from typing import Optional
from pydantic import BaseModel
from typing import Optional

class ScreenLocation(BaseModel):
    x: float
    y: float
    width: float
    height: float

class Step(BaseModel):
    thought: str
    action: str
    instruction: str
    element_description: Optional[str] = None
    screen_location: Optional[ScreenLocation] = None
    hover_before_action: bool = False
    text_input: Optional[str] = None
import json
import logging
from pydantic import BaseModel
from typing import Optional, Dict

logger = logging.getLogger(__name__)

class ScreenLocation(BaseModel):
    x: float
    y: float
    width: float
    height: float

class Step(BaseModel):
    thought: str
    action: str
    instruction: str
    element_description: Optional[str] = None
    screen_location: Optional[ScreenLocation] = None
    hover_before_action: bool = False
    text_input: Optional[str] = None

async def run_agent(question: str, start_url: str):
    print(f"run_agent called with question: {question}, start_url: {start_url}")
    
    # Load and parse app-metadata.json
    with open('src/app/sdk/metadata/app-metadata.json', 'r') as f:
        app_metadata = json.load(f)
    
    # Extract relevant information
    available_routes = [route['path'] for route in app_metadata.get('routes', [])]
    components = app_metadata.get('components', [])
    pages = app_metadata.get('pages', [])

    # Log the extracted information
    logger.debug(f"Available routes: {available_routes}")
    logger.debug(f"Number of components: {len(components)}")
    logger.debug(f"Number of pages: {len(pages)}")

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()
        try:
            print(f"Navigating to start_url: {start_url}")
            await page.goto(start_url, timeout=60000)
            logger.debug(f"Navigated to {start_url}")
            
            # Query Pinecone for relevant information
            pinecone_results = query_pinecone(question)
            relevant_info = "\n".join([result['metadata']['content'] for result in pinecone_results['matches']])

            # Augment the input with relevant information from Pinecone and app metadata
            augmented_input = f"""
            Goal: {question}

            Relevant information from Firecrawl docs:
            {relevant_info}

            Available routes:
            {', '.join(available_routes)}

            Number of components: {len(components)}
            Number of pages: {len(pages)}
            """

            event_stream = graph.astream(
                {
                    "page": page,
                    "input": augmented_input,
                    "scratchpad": [],
                    "current_url": page.url,
                    "action_history": [],
                    "html_content": "",
                    "text_content": "",
                    "app_metadata": app_metadata,
                    "available_routes": available_routes,  # Explicitly include available routes
                },
                {
                    "recursion_limit": 150,
                },
            )

            async for event in event_stream:
                if "agent" not in event:
                    continue
                
                state = event["agent"]
                pred = state.get("prediction") or {}
                action = pred.get("action")
                action_input = pred.get("args")
                thought = state.get("output", "").split("Thought:", 1)[-1].split("Action:", 1)[0].strip()

                # Check if the current action is a repeat of the last action
                action_history = state.get("action_history", [])
                if action_history and action_history[-1]["action"] == action and action_history[-1]["args"] == action_input:
                    logger.warning("Repeated action detected. Skipping.")
                    continue

                instruction = ""
                element_description = None
                screen_location = None
                hover_before_action = False
                text_input = None

                try:
                    if action in ["Click", "Type", "Scroll"]:
                        if action_input:
                            bbox_id = int(action_input[0])
                            bboxes = state.get("bboxes")
                            if bboxes and bbox_id < len(bboxes):
                                bbox = bboxes[bbox_id]
                                element_description = bbox.get("ariaLabel") or bbox.get("text") or f"element of type {bbox.get('type')}"
                                screen_location = {
                                    "x": bbox["x"],
                                    "y": bbox["y"],
                                    "width": bbox.get("width", 0),
                                    "height": bbox.get("height", 0)
                                }
                                hover_before_action = True

                                # Move cursor to the target location
                                await page.mouse.move(bbox["x"], bbox["y"])
                                
                                # Add a delay after moving the cursor
                                await asyncio.sleep(2)
                                logger.debug("Waited for 2 seconds after moving cursor")

                                if action == "Click":
                                    instruction = f"Click on the {element_description}."
                                    await page.mouse.click(bbox["x"], bbox["y"])
                                elif action == "Type":
                                    text_input = action_input[1]
                                    instruction = f"Type '{text_input}' into the {element_description}."
                                    await page.mouse.click(bbox["x"], bbox["y"])
                                    await page.keyboard.type(text_input)
                                elif action == "Scroll":
                                    direction = "up" if action_input[1].lower() == "up" else "down"
                                    instruction = f"Scroll {direction} in the {element_description}."
                                    await page.mouse.wheel(0, -100 if direction == "up" else 100)
                    elif action == "Wait":
                        instruction = "Wait for a moment while the page loads."
                        await asyncio.sleep(5)
                    elif action == "GoBack":
                        instruction = "Go back to the previous page."
                        await page.go_back()
                    elif action == "Home":
                        instruction = "Go back to home page."
                        await page.goto("http://localhost:3000/")
                    elif action.startswith("ANSWER"):
                        instruction = f"Task completed. Answer: {action_input[0]}"
                    else:
                        instruction = f"{action} {action_input}"
                except Exception as e:
                    logger.error(f"Error processing action: {str(e)}")

                yield {
                    "thought": thought,
                    "action": action,
                    "instruction": instruction,
                    "element_description": element_description,
                    "screen_location": screen_location,
                    "hover_before_action": hover_before_action,
                    "text_input": text_input
                }

                if action.startswith("ANSWER"):
                    break

        except Exception as e:
            logger.error(f"Error during agent execution: {str(e)}")
            yield {
                "thought": "Error occurred",
                "action": "ERROR",
                "instruction": f"An error occurred: {str(e)}",
                "element_description": None,
                "screen_location": None,
                "hover_before_action": False,
                "text_input": None
            }
        finally:
            await browser.close()

import asyncio

async def main():
    try:
        # Index Firecrawl docs
        index_documents('src/app/api/metadata/firecrawl.md')
        
        # Index the app-metadata.json file
        index_single_file('src/app/sdk/metadata/app-metadata.json')
        
        # Then run the agent
        await run_agent()
    except openai.AuthenticationError:
        print("Authentication error: Please check your OpenAI API key.")
    except openai.APIError as e:
        print(f"OpenAI API error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {str(e)}")
        import traceback
        traceback.print_exc()

# Main execution block
if __name__ == "__main__":
    asyncio.run(main())