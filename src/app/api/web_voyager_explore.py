# -*- coding: utf-8 -*-
"""web_voyager.ipynb
http://localhost:3000
Automatically generated by Colab.

uvicorn src.app.api.api:app --reload   

Original file is located at
    https://colab.research.google.com/github/albeorla/google-collab-notebooks/blob/main/web_voyager.ipynb
"""

import json
import os
import asyncio
import base64
import platform
import re
from typing import List, Optional, TypedDict
from dotenv import load_dotenv
from urllib.parse import urlparse

from langchain_core.messages import BaseMessage, SystemMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough, RunnableLambda, chain as chain_decorator
from langchain_openai import ChatOpenAI
from langchain import hub
from langgraph.graph import END, StateGraph
from playwright.async_api import Page, async_playwright
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Load environment variables
load_dotenv()

# Set up environment variables
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "Web-Voyager"
os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGCHAIN_API_KEY")
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# Define types
class BBox(TypedDict):
    x: float
    y: float
    text: str
    type: str
    ariaLabel: str

class Prediction(TypedDict):
    action: str # 
    args: Optional[List[str]]

class AgentState(TypedDict):
    page: Page # single page in browser, provides ways to interact with web pages
    input: str
    img: str
    bboxes: List[BBox]  # list of bounding boxes
    prediction: Prediction # another class defined above
    scratchpad: List[BaseMessage] # acts as the memory for the agent
    observation: str
    current_url: str
    action_history: List[dict]  # New field to store action history
    page_height: int  # Full page height
    viewport_height: int  # Visible viewport height
    html_content: str
    text_content: str

from pydantic import BaseModel

from pydantic import BaseModel
from typing import List, Optional

class ScreenLocation(BaseModel):
    x: float
    y: float
    width: float
    height: float

class Step(BaseModel):
    thought: str
    action: str
    instruction: str
    element_description: Optional[str] = None
    screen_location: Optional[dict] = None
    hover_before_action: bool = False
    text_input: Optional[str] = None

class AgentResponse(BaseModel):
    steps: List[Step]
    final_answer: Optional[str] = None
    current_url: str

###############
# AGENT TOOLS #
###############

# Define tools
async def click(state: AgentState):
    page = state["page"] # grab the page in browser
    # grab the action string list, args determined by agent b4 called
    click_args = state["prediction"]["args"]
    # if click_args above doesn't exist, click_args is expected to have one argument
    if click_args is None or len(click_args) != 1:
        return f"Failed to click bounding box labeled as number {click_args}"
    # accesses first element in click_args list, converts to int. alr decided what to click
    bbox_id = int(click_args[0])
    # access specific bounding box information
    try:
        bbox = state["bboxes"][bbox_id]
    except:
        return f"Error: no bbox for : {bbox_id}"
    # grab x and y coordinates
    x, y = bbox["x"], bbox["y"]
    # page.mouse.click() from playwrite object
    await page.mouse.click(x, y)
    return f"Clicked {bbox_id}" # returns a string

async def type_text(state: AgentState):
    # Get the page object from the state
    page = state["page"]
    # Get the typing arguments from the state
    type_args = state["prediction"]["args"]
    # Check if the arguments are valid
    if type_args is None or len(type_args) != 2:
        return f"Failed to type in element from bounding box labeled as number {type_args}"
    # Get the bounding box ID
    bbox_id = int(type_args[0])
    # Get the bounding box information
    bbox = state["bboxes"][bbox_id]
    # Extract x and y coordinates from the bounding box
    x, y = bbox["x"], bbox["y"]
    # Get the text to be typed
    text_content = type_args[1]
    # Click on the element at the specified coordinates
    await page.mouse.click(x, y)
    # Determine the "Select All" keyboard shortcut based on the operating system
    select_all = "Meta+A" if platform.system() == "Darwin" else "Control+A"
    # Select all existing text in the element
    await page.keyboard.press(select_all)
    # Delete the selected text
    await page.keyboard.press("Backspace")
    # Type the new text content
    await page.keyboard.type(text_content)
    # Press Enter to submit the input
    await page.keyboard.press("Enter")
    # Return a success message
    return f"Typed {text_content} and submitted"


async def scroll(state: AgentState):
    page = state["page"]
    scroll_args = state["prediction"]["args"]
    if scroll_args is None or len(scroll_args) != 2:
        return "Failed to scroll due to incorrect arguments. Please specify target and direction."

    target, direction = scroll_args

    if target.upper() == "WINDOW":
        vertical_scroll_amount = 500
        horizontal_scroll_amount = 300
        if direction.lower() == "up":
            scroll_x, scroll_y = 0, -vertical_scroll_amount
        elif direction.lower() == "down":
            scroll_x, scroll_y = 0, vertical_scroll_amount
        elif direction.lower() == "left":
            scroll_x, scroll_y = -horizontal_scroll_amount, 0
        elif direction.lower() == "right":
            scroll_x, scroll_y = horizontal_scroll_amount, 0
        else:
            return f"Invalid scroll direction: {direction}"
        await page.evaluate(f"window.scrollBy({scroll_x}, {scroll_y})")
    else:
        try:
            target_id = int(target)
            bbox = state["bboxes"][target_id]
            x, y = bbox["x"], bbox["y"]
            vertical_scroll_amount = 200
            horizontal_scroll_amount = 100
            if direction.lower() == "up":
                delta_x, delta_y = 0, -vertical_scroll_amount
            elif direction.lower() == "down":
                delta_x, delta_y = 0, vertical_scroll_amount
            elif direction.lower() == "left":
                delta_x, delta_y = -horizontal_scroll_amount, 0
            elif direction.lower() == "right":
                delta_x, delta_y = horizontal_scroll_amount, 0
            else:
                return f"Invalid scroll direction: {direction}"
            await page.mouse.move(x, y)
            await page.mouse.wheel(delta_x, delta_y)
        except ValueError:
            return f"Invalid target for scrolling: {target}"
        except IndexError:
            return f"Invalid bounding box ID: {target}"

    return f"Scrolled {direction} in {'window' if target.upper() == 'WINDOW' else f'element {target}'}"

async def wait(state: AgentState):
    sleep_time = 5
    # asyncio allows other funcs to continue while waiting
    await asyncio.sleep(sleep_time)
    return f"Waited for {sleep_time}s."

async def go_back(state: AgentState):
    page = state["page"]
    # playwright function
    await page.go_back()
    return f"Navigated back a page to {page.url}."

async def to_google(state: AgentState):
    page = state["page"]
    await page.goto("https://google.com")
    return "Navigated to Google."

async def to_home(state: AgentState):
    page = state["page"]
    await page.goto("https://tour-guide-liard.vercel.app/")
    return "Navigated to home page."


# Define mark_page function, THIS MARKS BOUNDING BOXES.
# done with the mark_page.js file
# Read mark_page.js
with open("/Users/williamphan/Desktop/tourguide/src/app/api/mark_page.js") as f:
    mark_page_script = f.read()

# decorator for chaining operations
# a way to wrap a function with another function, adding functionality before 
# or after the wrapped function executes
@chain_decorator
# asynchronous function to mark elements on the page
async def mark_page(page):
    await page.evaluate(mark_page_script)
    for _ in range(10):
        try:
            bboxes = await page.evaluate("markPage()")
            break
        except:
            await asyncio.sleep(2)
    screenshot = await page.screenshot()
    page_height = await page.evaluate("() => document.documentElement.scrollHeight")
    viewport_height = await page.evaluate("() => window.innerHeight")
    
    # Get HTML content
    html_content = await page.content()
    
    # Extract text content
    text_content = await page.evaluate("() => document.body.innerText")
    
    return {
        "img": base64.b64encode(screenshot).decode(),
        "bboxes": bboxes,
        "page_height": page_height,
        "viewport_height": viewport_height,
        "html_content": html_content,
        "text_content": text_content,
    }


# Define agent functions
async def annotate(state):
    marked_page = await mark_page.with_retry().ainvoke(state["page"])
    current_url = state["page"].url
    return {**state, **marked_page, "current_url": current_url}


# define function that takes a state parameter
def format_descriptions(state):
    # initialize an empty list to store formatted labels
    labels = []
    # iterate over bounding boxes in state, with index
    for i, bbox in enumerate(state["bboxes"]):
        # get ariaLabel if it exists, otherwise empty string
        text = bbox.get("ariaLabel") or ""
        # if text is empty or only whitespace, use bbox text instead
        if not text.strip():
            text = bbox["text"]
        # get the type of the element
        el_type = bbox.get("type")
        # append formatted string to labels list
        labels.append(f'{i} (<{el_type}/>): "{text}"')
    # create a string of all labels, joined by newlines
    bbox_descriptions = "\nValid Bounding Boxes:\n" + "\n".join(labels)
    
    # Format action history
    action_history = state.get("action_history", [])
    formatted_history = "\n".join([f"{a['step']}. {a['action']} {a['args']} (URL: {a['url']})" for a in action_history])
    
    page_info = f"Page height: {state['page_height']}px, Viewport height: {state['viewport_height']}px"
    
    # Include a summary of the text content
    text_summary = state['text_content'][:500] + "..." if len(state['text_content']) > 500 else state['text_content']
    
    return {**state, "bbox_descriptions": bbox_descriptions, "action_history": formatted_history, "page_info": page_info, "text_summary": text_summary}


def parse(text: str) -> dict:
    action_prefix = "Action: "
    if not text.strip().split("\n")[-1].startswith(action_prefix):
        return {"action": "retry", "args": f"Could not parse LLM Output: {text}"}
    action_block = text.strip().split("\n")[-1]

    action_str = action_block[len(action_prefix):]
    split_output = action_str.split(" ", 1)
    if len(split_output) == 1:
        action, action_input = split_output[0], None
    else:
        action, action_input = split_output
    action = action.strip()
    if action_input is not None:
        action_input = [inp.strip().strip("[]") for inp in action_input.strip().split(";")]
    return {"action": action, "args": action_input}


"""
crucial for maintaining the agent's "memory" and providing it with a structured history of its interactions. This history is vital for the agent to perform complex, multi-step tasks on web pages, as it allows the agent to reference past actions, understand the current context, and make more informed decisions about what to do next.
"""

def update_scratchpad(state: AgentState):
    # Get the existing scratchpad from the state, if any
    old = state.get("scratchpad")
    action_history = state.get("action_history", [])
    
    if old:
        # If there's an existing scratchpad, get its content
        txt = old[0].content
        # Extract the last line of the existing content
        last_line = txt.rsplit("\n", 1)[-1]
        # Extract the step number from the last line and increment it
        step = int(re.match(r"\d+", last_line).group()) + 1
    else:
        # If there's no existing scratchpad, initialize with a header
        txt = "Previous action observations:\n"
        # Start with step 1
        step = 1
    
    # Add the new observation to the text, with the current step number
    txt += f"\n{step}. {state['observation']}"
    
    # Add the current action to the history
    action_history.append({
        "step": step,
        "action": state['prediction']['action'],
        "args": state['prediction']['args'],
        "url": state['current_url']
    })
    
    # Limit the history to the last 10 actions
    action_history = action_history[-10:]
    
    # Return updated state with new scratchpad content
    # The scratchpad is a list containing a single SystemMessage
    return {**state, "scratchpad": [SystemMessage(content=txt)], "action_history": action_history}

# Set up the agent
# https://smith.langchain.com/hub/wfh/web-voyager?organizationId=2fe448c8-5ad1-583b-96a3-e1a7e2c8b466
# prompt = hub.pull("wfh/web-voyager")

custom_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a web navigation assistant. Your task is to guide the user based on their specific query or request. 
    In each iteration, you will receive an Observation that includes a screenshot of a webpage, some texts, and the current URL. 
    This screenshot will feature Numerical Labels placed in the TOP LEFT corner of each Web Element. 
    Carefully analyze the visual information, HTML content, and the current URL to determine your next action.

    Current goal: {input}

    Choose one of the following actions:
    1. Click a Web Element.
    2. Delete existing content in a textbox and then type content.
    3. Scroll up, down, left, or right to explore parts of the page that might not be visible.
    4. Wait 
    5. Go back
    6. Return to the home page to start over.
    7. Respond with the final answer

    Action should STRICTLY follow the format:
    - Click [Numerical_Label] 
    - Type [Numerical_Label]; [Content] 
    - Scroll [Numerical_Label or WINDOW]; [up or down or left or right] 
    - Wait 
    - GoBack
    - Home
    - ANSWER; [content]

    Key Guidelines:
    1) Execute only one action per iteration.
    2) When clicking or typing, ensure to select the correct bounding box.
    3) Numeric labels lie in the top-left corner of their corresponding bounding boxes and are colored the same.
    4) When you have completed the task or cannot proceed further, respond with ANSWER and do not perform any further actions.
    5) Pay close attention to the current URL, page content, and HTML structure to determine if you've reached the desired page or information.
    6) Avoid repeating the same action multiple times in a row.
    7) If you find yourself in a loop, try a different approach or consider ending the task.
    8) Remember to scroll to explore parts of the page that might not be initially visible.
    9) When scrolling, always specify both the target (WINDOW or a Numerical_Label) and the direction (up, down, left, or right).
    10) Analyze the text content of the page to make informed decisions.

    Your reply should strictly follow the format:
    Thought: {{Your brief thoughts}}
    Action: {{One Action format you choose}}"""),
    MessagesPlaceholder(variable_name="scratchpad"),
    ("human", "{input}\n\n{bbox_descriptions}\n\nCurrent URL: {current_url}\n\nPage Info: {page_info}\n\nText Content Summary:\n{text_summary}\n\nAction History:\n{action_history}"),
])

# Replace the existing prompt with the custom one
prompt = custom_prompt
llm = ChatOpenAI(model="gpt-4o-mini", max_tokens=4096)
agent = annotate | RunnablePassthrough.assign(
    # | is used to chain operations together in order
    # StrOutputParser() parses into string, parse processes stirng output into structured format.
    prediction=format_descriptions | prompt | llm | StrOutputParser() | parse
)

####################
# INITIALIZE GRAPH #
####################

# Set up/initialize the graph, pass in the agent state
graph_builder = StateGraph(AgentState)


# define node
graph_builder.add_node("agent", agent)
# sents the agent node to be first node to be excecuted when running
graph_builder.set_entry_point("agent")
# define other node
graph_builder.add_node("update_scratchpad", update_scratchpad)
# define edge between both the nodes
# Agent makes a decision
# An action is taken based on that decision
# The scratchpad is updated with the result of that action
# Control returns to the agent for the next decision
graph_builder.add_edge("update_scratchpad", "agent")

# agent tools
tools = {
    "Click": click,
    "Type": type_text,
    "Scroll": scroll,
    "Wait": wait,
    "GoBack": go_back,
    "Home": to_home, 
}

# Add nodes for each tool and connect them to the scratchpad update
for node_name, tool in tools.items():
    graph_builder.add_node(
        node_name,
        # Combine tool execution with formatting its output
        RunnableLambda(tool) | (lambda observation: {"observation": observation}),
    )
    # After each tool execution, update the scratchpad
    graph_builder.add_edge(node_name, "update_scratchpad")

# Function to select the next action based on the agent's prediction
def select_tool(state: AgentState):
    action = state["prediction"]["action"]
    if action.startswith("ANSWER"):
        return END  # End the process if the action is to answer
    if action == "retry":
        return "agent"  # Go back to the agent if a retry is needed
    return action  # Otherwise, return the action name (corresponding to a tool)

# Add conditional edges from the agent to other nodes based on select_tool function
graph_builder.add_conditional_edges("agent", select_tool)

# Compile the graph, making it ready for execution
graph = graph_builder.compile()

#############
# RUN AGENT #
#############
import os
from pinecone import Pinecone
from pinecone import Pinecone, ServerlessSpec
from openai import OpenAI
from typing import List
import openai
from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type

# Initialize Pinecone
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
index_name = os.getenv("PINECONE_INDEX_NAME")

if not index_name:
    raise ValueError("PINECONE_INDEX_NAME environment variable is not set")

# Check if the index exists, if not, create it
try:
    if index_name not in pc.list_indexes().names():
        pc.create_index(
            name=index_name,
            dimension=1536,  # OpenAI's ada-002 embedding dimension
            metric='cosine', # uses cosine similarity
          spec=ServerlessSpec(
                cloud="aws",
                region="us-east-1"
            ) 
        )
    index = pc.Index(index_name)
except Exception as e:
    print(f"Error initializing Pinecone: {str(e)}")
    raise

# Initialize OpenAI client
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@retry(
    wait=wait_random_exponential(min=1, max=60),
    stop=stop_after_attempt(6),
    retry=retry_if_exception_type(openai.RateLimitError)
)
def create_embedding_with_retry(text: str) -> List[float]:
    try:
        response = openai_client.embeddings.create(
            input=text,
            model="text-embedding-ada-002"
        )
        return response.data[0].embedding
    except openai.RateLimitError as e:
        print(f"Rate limit error: {e}")
        raise
    except openai.APIError as e:
        print(f"API error: {e}")
        if "billing_not_active" in str(e):
            print("Please check your OpenAI account billing status at https://platform.openai.com/account/billing")
            raise ValueError("OpenAI account is not active") from e
        raise

def create_embedding(text: str) -> List[float]:
    if len(text.split()) > 8000:  # Approximate token count
        return create_embedding_chunked(text)
    else:
        return create_embedding_with_retry(text)

def create_embedding_chunked(text):
    chunks = chunk_text(text)
    embeddings = []
    for chunk in chunks:
        embedding = create_embedding(chunk)
        embeddings.append(embedding)
    return np.mean(embeddings, axis=0).tolist()  # Average the embeddings

def chunk_text(text, max_tokens=8000):
    words = text.split()
    chunks = []
    current_chunk = []
    current_count = 0

    for word in words:
        if current_count + len(word) + 1 > max_tokens:
            chunks.append(' '.join(current_chunk))
            current_chunk = [word]
            current_count = len(word)
        else:
            current_chunk.append(word)
            current_count += len(word) + 1

    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks

def upsert_to_pinecone(file_path: str, file_content: str):
    embedding = create_embedding(file_content)
    index.upsert(vectors=[(file_path, embedding, {"content": file_content})])

def query_pinecone(query: str, top_k: int = 3):
    query_embedding = create_embedding(query)
    # Print the query and its embedding
    print(f"Query: {query}")
    print(f"Query Embedding (first 5 dimensions): {query_embedding[:5]}...")
    
    results = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)
    # Print the results
    print("\nTop matching documents:")
    for i, match in enumerate(results['matches'], 1):
        print(f"\n{i}. Score: {match['score']}")
        print(f"   ID: {match['id']}")
        print(f"   Content snippet: {match['metadata']['content'][:100]}...")
    
    return results

def index_documents(directory: str):
    print(f"Indexing documents from {directory}...")
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith(('.md', '.json')):
                file_path = os.path.join(root, file)
                with open(file_path, 'r') as f:
                    content = f.read()
                upsert_to_pinecone(file_path, content)
    print(f"Indexing complete for {directory}")

def index_single_file(file_path: str):
    print(f"Indexing single file: {file_path}")
    with open(file_path, 'r') as f:
        content = f.read()
    upsert_to_pinecone(file_path, content)
    print(f"Indexing complete for {file_path}")


"""
The system takes context from all the markdown and JSON files (via Pinecone), and it also uses GPT-4. It's not solely using GPT-4, but rather combining the power of vector search (Pinecone) with the language understanding and generation capabilities of GPT-4.

The reason why the augmented input attached to the question is because:
• The question is augmented with RELEVANT Pinecone data.
• This augmented input is passed to the agent.
• The agent uses the prompt (which includes placeholders for the input and other data) to structure its response.
"""

# Main function to run the agent
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

import logging
import json
from pydantic import BaseModel

from pydantic import BaseModel
from typing import Optional
from pydantic import BaseModel
from typing import Optional

class ScreenLocation(BaseModel):
    x: float
    y: float
    width: float
    height: float

class Step(BaseModel):
    thought: str
    action: str
    instruction: str
    element_description: Optional[str] = None
    screen_location: Optional[ScreenLocation] = None
    hover_before_action: bool = False
    text_input: Optional[str] = None
import json
import logging
from pydantic import BaseModel
from typing import Optional, Dict

logger = logging.getLogger(__name__)

class ScreenLocation(BaseModel):
    x: float
    y: float
    width: float
    height: float

class Step(BaseModel):
    thought: str
    action: str
    instruction: str
    element_description: Optional[str] = None
    screen_location: Optional[ScreenLocation] = None
    hover_before_action: bool = False
    text_input: Optional[str] = None

async def explore_website(start_url: str):
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto(start_url)

        site_map = {}
        visited_urls = set()
        await explore_page(page, start_url, site_map, visited_urls)

        await browser.close()
        return site_map

async def explore_page(page, url, site_map, visited_urls):
    if url in visited_urls:
        return

    visited_urls.add(url)
    await page.goto(url)
    
    # Extract page elements and features
    elements = await page.evaluate("""() => {
        return Array.from(document.querySelectorAll('*')).map(el => ({
            tag: el.tagName,
            id: el.id,
            classes: Array.from(el.classList),
            text: el.innerText,
            href: el.href,
            rect: el.getBoundingClientRect().toJSON()
        }));
    }""")

    site_map[url] = {
        'elements': elements,
        'links': []
    }

    # Find all links on the page
    links = await page.evaluate("""() => {
        return Array.from(document.links).map(a => a.href);
    }""")

    for link in links:
        if link.startswith(start_url) and link not in visited_urls:
            site_map[url]['links'].append(link)
            await explore_page(page, link, site_map, visited_urls)

def detect_state(current_url: str, current_elements: list, site_map: dict):
    best_match = None
    best_score = 0

    for url, page_data in site_map.items():
        score = calculate_similarity(current_elements, page_data['elements'])
        if score > best_score:
            best_score = score
            best_match = url

    return best_match

def calculate_similarity(elements1, elements2):
    # Implement a similarity calculation between two sets of elements
    # This could be based on matching IDs, classes, text content, etc.
    pass

def find_shortest_path(start_state: str, end_state: str, site_map: dict):
    graph = {url: data['links'] for url, data in site_map.items()}
    queue = [(start_state, [start_state])]
    visited = set()

    while queue:
        (state, path) = queue.pop(0)
        if state not in visited:
            visited.add(state)

            if state == end_state:
                return path

            for next_state in graph[state]:
                if next_state not in visited:
                    queue.append((next_state, path + [next_state]))

    return None

def generate_instructions(path: list, site_map: dict):
    instructions = []
    for i in range(len(path) - 1):
        current_state = path[i]
        next_state = path[i+1]
        
        # Find the element that links to the next state
        for element in site_map[current_state]['elements']:
            if element['href'] == next_state:
                instructions.append(f"Click on the element with text '{element['text']}'")
                break
    
    return instructions

def determine_target_state(question: str, site_map: dict):
    # Create a TF-IDF vectorizer
    vectorizer = TfidfVectorizer()

    # Prepare the documents (page contents)
    documents = []
    urls = []
    for url, data in site_map.items():
        # Combine all text content from the page
        page_text = ' '.join([elem['text'] for elem in data['elements'] if elem['text']])
        documents.append(page_text)
        urls.append(url)

    # Fit and transform the documents
    tfidf_matrix = vectorizer.fit_transform(documents)

    # Transform the question
    question_vector = vectorizer.transform([question])

    # Calculate cosine similarity between the question and each document
    similarities = cosine_similarity(question_vector, tfidf_matrix)

    # Find the index of the most similar document
    most_similar_index = similarities.argmax()

    # Return the URL of the most similar page
    return urls[most_similar_index]

async def run_agent(question: str, start_url: str):
    # First, explore and map the website
    site_map = await explore_website(start_url)

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()
        await page.goto(start_url)

        try:
            # Detect current state
            current_elements = await page.evaluate("""() => {
                return Array.from(document.querySelectorAll('*')).map(el => ({
                    tag: el.tagName,
                    id: el.id,
                    classes: Array.from(el.classList),
                    text: el.innerText,
                    href: el.href,
                    rect: el.getBoundingClientRect().toJSON()
                }));
            }""")
            current_state = detect_state(page.url, current_elements, site_map)

            # Determine target state based on the question
            target_state = determine_target_state(question, site_map)

            # Find the shortest path
            path = find_shortest_path(current_state, target_state, site_map)

            # Generate instructions
            instructions = generate_instructions(path, site_map)

            # Use the existing agent to follow the instructions
            for instruction in instructions:
                # Implement logic to have the agent follow each instruction
                pass

            # Final answer generation
            final_answer = generate_final_answer(question, page)

            yield {
                "thought": "Task completed",
                "action": "ANSWER",
                "instruction": f"Here are the steps to reach the answer: {', '.join(instructions)}",
                "final_answer": final_answer
            }

        except Exception as e:
            yield {
                "thought": "Error occurred",
                "action": "ERROR",
                "instruction": f"An error occurred: {str(e)}",
            }
        finally:
            await browser.close()

import asyncio

async def main():
    try:
        # Index Firecrawl docs
        index_documents('src/app/api/metadata/firecrawl.md')
        
        # Index the app-metadata.json file
        index_single_file('src/app/sdk/metadata/app-metadata.json')
        
        # Then run the agent
        await run_agent()
    except openai.AuthenticationError:
        print("Authentication error: Please check your OpenAI API key.")
    except openai.APIError as e:
        print(f"OpenAI API error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {str(e)}")
        import traceback
        traceback.print_exc()

# Main execution block
if __name__ == "__main__":
    asyncio.run(main())